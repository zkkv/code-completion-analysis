{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from evaluate import load \n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: read all files into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 file(s) have been read in directory ../data\n"
     ]
    }
   ],
   "source": [
    "def read_files(directory_path: str, filenames: list[str]) -> list[str]:\n",
    "\tfile_contents = []\n",
    "\n",
    "\tfor filename in filenames:\n",
    "\t\tfile_path = os.path.join(directory_path, filename)\n",
    "\n",
    "\t\twith open(file_path, 'r') as file:\n",
    "\t\t\tfile_contents.append(file.read())\n",
    "\n",
    "\treturn file_contents\n",
    "\n",
    "\n",
    "in_directory_path = \"../data\"\n",
    "filenames = os.listdir(in_directory_path)\n",
    "contents = read_files(in_directory_path, filenames)\n",
    "n_files = len(contents)\n",
    "\n",
    "print(f\"{n_files} file(s) have been read in directory {in_directory_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: split each file into three parts multiple times\n",
    "\n",
    "`split_data` will be of dimensions `[n_files x n_samples x 3]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_data has been initialized with 1 sample(s) per file\n"
     ]
    }
   ],
   "source": [
    "def split(n_samples: int, min_missing_chars: int, max_missing_chars: int) -> list[list[list[str]]]:\n",
    "\tsplit_data = []\n",
    "\n",
    "\tfor file_content in contents:\n",
    "\t\tfile_splits = []\n",
    "\t\tfor _ in range(n_samples):\n",
    "\t\t\tmiddle_len = min(len(file_content), random.randint(min_missing_chars, max_missing_chars))\n",
    "\t\t\tmiddle_start = random.randint(0, len(file_content) - 1 - middle_len)\n",
    "\t\t\tmiddle_end = middle_start + middle_len\n",
    "\n",
    "\t\t\tprefix = file_content[:middle_start]\n",
    "\t\t\tmiddle = file_content[middle_start:middle_end]\n",
    "\t\t\tsuffix = file_content[middle_end:]\n",
    "\n",
    "\t\t\tfile_splits.append([prefix, middle, suffix])\n",
    "\t\tsplit_data.append(file_splits)\n",
    "\treturn split_data\n",
    "\n",
    "\n",
    "n_samples = 1  # Number of different splits obtained per file. Total number of samples = n_files * n_samples\n",
    "max_missing_chars = 50  # The maximum number of characters that need to be completed (i.e. the middle part)\n",
    "min_missing_chars = 5\n",
    "random.seed(45)  # For reproducible results\n",
    "\n",
    "split_data = split(n_samples, min_missing_chars, max_missing_chars)\n",
    "\n",
    "print(f\"split_data has been initialized with {n_samples} sample(s) per file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3.1: Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_login() -> None:\n",
    "\tload_dotenv()\n",
    "\tapi_key = os.getenv('HUGGINGFACE_TOKEN')\n",
    "\tlogin(api_key)\n",
    "\n",
    "\n",
    "def load_model(model_name: str, device: str):\n",
    "\ttokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\ttokenizer.pad_token = tokenizer.eos_token\n",
    "\tmodel = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.bfloat16).to(device)\n",
    "\treturn model, tokenizer\n",
    "\n",
    "\n",
    "hf_login()\n",
    "device = \"cpu\"\n",
    "model_name = \"bigcode/starcoderbase-1b\"\n",
    "model, tokenizer = load_model(model_name, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3.2: Use the model to generate suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest(model, tokenizer, prefix: str, suffix: str) -> str:\n",
    "\tPREFIX_TAG = \"<fim_prefix>\"\n",
    "\tSUFFIX_TAG = \"<fim_suffix>\"\n",
    "\tMIDDLE_TAG = \"<fim_middle>\"\n",
    "\tEOT_TAG = \"<|endoftext|>\"\n",
    "\t\n",
    "\tinput_text = f\"{PREFIX_TAG}{prefix}{SUFFIX_TAG}{suffix}{MIDDLE_TAG}\"\n",
    "\tinputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\toutputs = model.generate(inputs, max_new_tokens=max_missing_chars, pad_token_id=tokenizer.pad_token_id)\n",
    "\tresult = tokenizer.decode(outputs[0])\n",
    "\treturn result.split(MIDDLE_TAG)[-1].replace(EOT_TAG, '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_suggestions = []\n",
    "\n",
    "for i in range(n_files):\n",
    "\tfile_suggestions = []\n",
    "\tfor j in range(n_samples):\n",
    "\t\tsuggestion = suggest(model, tokenizer, split_data[i][j][0], split_data[i][j][2])\n",
    "\t\tfile_suggestions.append(suggestion)\n",
    "\traw_suggestions.append(file_suggestions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Collect the results in a CSV file and as source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_table(table_directory_path: str, table_name: str, table: pd.DataFrame) -> None:\n",
    "\tif table_directory_path[-1] != \"/\":\n",
    "\t\ttable_directory_path += \"/\"\n",
    "\tfull_path = f\"{table_directory_path}{table_name}\"\n",
    "\ttable.to_csv(full_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Original</th>\n",
       "      <th>Suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animal.py</td>\n",
       "      <td>f):\\n\\t\\tself.weight_kg =</td>\n",
       "      <td>f):\\n\\t\\tself.weight_kg = 10\\n\\t\\tself.sound =...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>add.py</td>\n",
       "      <td>sum of two numbers\\ndef add(a, b):\\n\\t</td>\n",
       "      <td>the sum of two numbers\\ndef add(a, b):\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        File                                 Original  \\\n",
       "0  animal.py                f):\\n\\t\\tself.weight_kg =   \n",
       "1     add.py   sum of two numbers\\ndef add(a, b):\\n\\t   \n",
       "\n",
       "                                          Suggestion  \n",
       "0  f):\\n\\t\\tself.weight_kg = 10\\n\\t\\tself.sound =...  \n",
       "1       the sum of two numbers\\ndef add(a, b):\\n      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_results_table() -> pd.DataFrame:\n",
    "\tdata = []\n",
    "\tfor i in range(n_files):\n",
    "\t\tfile_name = filenames[i]\n",
    "\t\tfor j in range(n_samples):\n",
    "\t\t\trow = {\n",
    "\t\t\t\t\"File\": file_name,\n",
    "\t\t\t\t\"Original\": split_data[i][j][1],\n",
    "\t\t\t\t\"Suggestion\": raw_suggestions[i][j]\n",
    "\t\t\t}\n",
    "\t\t\tdata.append(row)\n",
    "\n",
    "\treturn pd.DataFrame(data)\n",
    "\n",
    "\n",
    "table_directory_path = \"../out/tables\"\n",
    "results_table = get_results_table()\n",
    "display(results_table)\n",
    "write_table(table_directory_path, \"results.csv\", results_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_number_to_filename(filename: str, number: int) -> str:\n",
    "\tname, extension = filename.split(\".\")\n",
    "\treturn f\"{name}_{number}.{extension}\"\n",
    "\n",
    "\n",
    "def reconstruct_data(prefix: str, middle: str, suffix: str) -> str:\n",
    "\treturn prefix + middle + suffix\n",
    "\n",
    "\n",
    "def write_file(directory_path: str, filename: str, data: str) -> None:\n",
    "\tfile_path = os.path.join(directory_path, filename)\n",
    "\n",
    "\twith open(file_path, 'w') as file:\n",
    "\t\tfile.write(data)\n",
    "\n",
    "\n",
    "def write_files(directory_path: str) -> None:\n",
    "\tfor i in range(n_files):\n",
    "\t\tfor j in range(n_samples):\n",
    "\t\t\tfilename = append_number_to_filename(filenames[i], j)\n",
    "\t\t\tdata = reconstruct_data(split_data[i][j][0], raw_suggestions[i][j], split_data[i][j][2])\n",
    "\t\t\twrite_file(directory_path, filename, data)\n",
    "\n",
    "\n",
    "out_directory_path = \"../out\"\n",
    "write_files(out_directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Calculate metrics for the suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(original_data: list[str], suggested_data: list[str]) -> float:\n",
    "\treturn load(\"exact_match\").compute(predictions=suggested_data, references=original_data)[\"exact_match\"].item()\n",
    "\n",
    "def chrf(original_data: list[str], suggested_data: list[str]) -> float:\n",
    "\treturn load(\"chrf\").compute(predictions=suggested_data, references=original_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 0.0, 'chrf': {'score': 74.85498662263461, 'char_order': 6, 'word_order': 0, 'beta': 2}}\n"
     ]
    }
   ],
   "source": [
    "def flatten_results(split_data: list[list[list[str]]], suggestions: list[list[str]]) \\\n",
    "\t\t-> tuple[list[str], list[str]]:\n",
    "\toriginal_data = []\n",
    "\tsuggested_data = []\n",
    "\n",
    "\tfor i in range(n_files):\n",
    "\t\tfor j in range(n_samples):\n",
    "\t\t\toriginal_data.append(split_data[i][j][1])\n",
    "\t\t\tsuggested_data.append(suggestions[i][j])\n",
    "\n",
    "\treturn original_data, suggested_data\n",
    "\n",
    "\n",
    "def calculate_metrics(original_data: list[str], suggested_data: list[str]) -> dict[str, any]:\n",
    "\tmetrics = dict()\n",
    "\n",
    "\tmetrics[\"exact_match\"] = exact_match(original_data, suggested_data)\n",
    "\tmetrics[\"chrf\"] = chrf(original_data, suggested_data)\n",
    "\n",
    "\treturn metrics\n",
    "\n",
    "original_data, suggested_data = flatten_results(split_data, raw_suggestions)\n",
    "metrics = calculate_metrics(original_data, suggested_data)\n",
    "print(metrics)\n",
    "write_table(table_directory_path, \"metrics.csv\", pd.DataFrame(metrics))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
